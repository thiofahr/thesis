{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d265937",
   "metadata": {},
   "source": [
    "# Wave Filter Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import netCDF4\n",
    "from scipy import signal\n",
    "\n",
    "# Create a class for wave filtering\n",
    "class WaveFilter:\n",
    "    def __init__(self, ds, var, coverage, wave_name, n, units):\n",
    "        #self.path       = path\n",
    "        self.var        = var\n",
    "        self.coverage  = coverage\n",
    "        self.wave_name  = wave_name\n",
    "        self.long_name  = None\n",
    "        self.n          = n          \n",
    "\n",
    "        self.ds         = ds #xr.open_dataset(path,chunks={'time': 'auto'})  # 使用 dask 分块加载\n",
    "        self.data       = None\n",
    "        self.units      = units\n",
    "\n",
    "        self.filtered_data = None\n",
    "        self.fftdata       = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the data\"\"\"\n",
    "        var = self.var      # data variable\n",
    "\n",
    "        # adjust the dimension\n",
    "        if \"latitude\" in self.ds.coords:\n",
    "            self.ds = self.ds.rename({'latitude':'lat'})\n",
    "        if \"longitude\" in self.ds.coords:\n",
    "            self.ds = self.ds.rename({'longitude':'lon'})\n",
    "        if \"depth\" in self.ds.coords:\n",
    "            self.ds = self.ds.mean(\"depth\")\n",
    "\n",
    "        # load the data\n",
    "        self.data = self.ds[var].sel(**self.coverage).sortby('lat').transpose('time', 'lat', 'lon')\n",
    "        self.data = self.data.fillna(0)             # fill NaN value with 0 to avoid error\n",
    "        self.data = self.data.chunk({'time': -1})   # chunk the data for parallel processing\n",
    "        \n",
    "    def detrend_data(self):\n",
    "        \"\"\"Detrend the data using dask for parallel processing.\"\"\"\n",
    "        ntim, nlat, nlon = self.data.shape\n",
    "        spd = 1 # number of sample per day\n",
    "        #data_rechunked = self.data.data.rechunk({0: -1})\n",
    "        data_rechunked = self.data.data.rechunk({0: -1, 2: -1})\n",
    "        if ntim >  365*spd/3:\n",
    "            # FFT\n",
    "            rf   = da.fft.rfft(data_rechunked, axis=0)\n",
    "            freq = da.fft.rfftfreq(ntim * spd, d=1. / float(spd))\n",
    "            rf[(freq <= 3. / 365) & (freq >= 1. / 365), :, :] = 0.0\n",
    "            datain = da.fft.irfft(rf, axis=0, n=ntim)\n",
    " \n",
    "        # detrend the data\n",
    "        self.detrend = da.apply_along_axis(signal.detrend, 0, datain)    \n",
    "        # apply window function \n",
    "        window = signal.windows.tukey(ntim,0.05,True)\n",
    "        self.detrend = self.detrend * window[:, np.newaxis, np.newaxis]   \n",
    "\n",
    "    def fft_transform(self):\n",
    "        \"\"\"Perform 2D FFT on the detrended data using dask.\"\"\"\n",
    "        self.wavenumber = -da.fft.fftfreq(self.data.shape[2]) * self.data.shape[2]   # shape: (lon,)\n",
    "        self.frequency  = da.fft.fftfreq(self.data.shape[0], d=1./float(1))          # shape: (time,)\n",
    "\n",
    "        self.knum_ori, self.freq_ori = da.meshgrid(self.wavenumber, self.frequency)  # shape: (time, lon)\n",
    "        self.knum = self.knum_ori.copy()\n",
    "        self.knum = da.where(self.freq_ori < 0, -self.knum_ori, self.knum_ori)       # shape: (time, lon)\n",
    "        \n",
    "        self.freq = da.abs(self.freq_ori)    # shape: (time, lon)\n",
    "    \n",
    "    def apply_filter(self):\n",
    "        \"\"\"Apply filter based on wave type.\"\"\"\n",
    "        if self.wave_name.lower() == \"kw\":\n",
    "            self.tMin, self.tMax = 20, 180\n",
    "            self.kmin, self.kmax = 1, 14\n",
    "            self.hmin, self.hmax = None, None #0.025, 90\n",
    "            \n",
    "        elif self.wave_name.lower() == \"er\":\n",
    "            self.tMin, self.tMax = 180, 450\n",
    "            self.kmin, self.kmax = -10, -1\n",
    "            self.hmin, self.hmax = None, None #0.003, 90\n",
    "            \n",
    "        print(f\"T: {self.tMin}-{self.tMax} days | k: {self.kmin}-{self.kmax} | h = {self.hmin}-{self.hmax} m\")\n",
    "        \n",
    "        self.fmin, self.fmax = 1 / self.tMax, 1 / self.tMin\n",
    "        self.mask =  da.zeros((self.data.shape[0], self.data.shape[2]), dtype=bool)\n",
    "\n",
    "        if self.kmin is not None:\n",
    "            self.mask = self.mask | (self.knum < self.kmin)\n",
    "        if self.kmax is not None:\n",
    "            self.mask = self.mask | (self.kmax < self.knum)\n",
    "\n",
    "        if self.fmin is not None:\n",
    "            self.mask = self.mask | (self.freq < self.fmin)\n",
    "        if self.fmax is not None:\n",
    "            self.mask = self.mask | (self.fmax < self.freq)\n",
    "\n",
    "        if self.wave_name.lower() == 'kw':\n",
    "            self.apply_wave_filter(self.wave_name)\n",
    "        elif self.wave_name.lower() == 'er':\n",
    "            self.apply_wave_filter(self.wave_name)\n",
    "            \n",
    "        self.fftdata = da.fft.fft2(self.detrend, axes=(0, 2)) # shape: (time, lat, lon)\n",
    "        self.mask    = da.repeat(self.mask[:, np.newaxis, :], self.data.shape[1], axis=1)\n",
    "        self.fftdata = da.where(self.mask, 0.0, self.fftdata)\n",
    "\n",
    "    def apply_wave_filter(self, wave_name):\n",
    "        \"\"\"Apply equtorial wave filter.\"\"\"\n",
    "        # parameters\n",
    "        g    = 9.8\n",
    "        beta = 2.28e-11\n",
    "        a    = 6.37e6\n",
    "        n    = self.n\n",
    "\n",
    "        if self.wave_name.lower() == \"kw\":\n",
    "            if self.hmin is not None:\n",
    "                c      = da.sqrt(g * self.hmin)\n",
    "                omega  = 2. * np.pi * self.freq / 24. / 3600. / da.sqrt(beta * c)\n",
    "                k      = self.knum / a * da.sqrt(c / beta)\n",
    "                self.mask = self.mask | (omega - k < 0)\n",
    "            if self.hmax is not None:\n",
    "                c      = da.sqrt(g * self.hmax)\n",
    "                omega  = 2. * np.pi * self.freq / 24. / 3600. / da.sqrt(beta * c)\n",
    "                k      = self.knum / a * da.sqrt(c / beta)\n",
    "                self.mask = self.mask | (omega - k > 0)\n",
    "    \n",
    "        if self.wave_name.lower() == \"er\": \n",
    "            if self.hmin is not None:\n",
    "                c = da.sqrt(g * self.hmin)\n",
    "                omega = 2. * np.pi * self.freq / 24. / 3600. / da.sqrt(beta * c)\n",
    "                k = self.knum / a * da.sqrt(c / beta)\n",
    "                self.mask = self.mask | (omega * (k ** 2 + (2 * n + 1)) + k < 0)\n",
    "            if self.hmax is not None:\n",
    "                c = da.sqrt(g * self.hmax)\n",
    "                omega = 2. * np.pi * self.freq / 24. / 3600. / da.sqrt(beta * c)\n",
    "                k = self.knum / a * da.sqrt(c / beta)\n",
    "                self.mask = self.mask | (omega * (k ** 2 + (2 * n + 1)) + k > 0)\n",
    "         \n",
    "    def inverse_fft(self):\n",
    "        \"\"\"Perform inverse FFT to get the filtered data.\"\"\"\n",
    "        self.filtered_data = da.fft.ifft2(self.fftdata, axes=(0, 2)).real\n",
    "    \n",
    "    def create_output(self):\n",
    "        \"\"\"Create xarray DataArray for filtered data.\"\"\"\n",
    "    \n",
    "        if self.wave_name == 'KW':\n",
    "            self.long_name = 'Kelvin Waves'\n",
    "        elif 'ER' in self.wave_name:\n",
    "            self.long_name = 'Equatorial Rossby Waves'\n",
    "        else:\n",
    "            self.wave_name = None\n",
    "        \n",
    "        self.wave_data = xr.DataArray(self.filtered_data.compute(),\n",
    "                                      coords = {'time': self.data.time,\n",
    "                                                'lat' : self.data.lat,\n",
    "                                                'lon' : self.data.lon},\n",
    "                                      dims=['time', 'lat', 'lon'])\n",
    "        self.wave_data.attrs.update({\n",
    "            'name'           : self.wave_name,\n",
    "            'long_name'      : self.long_name,\n",
    "            'min_wavenumber' : self.kmin,\n",
    "            'max_wavenumber' : self.kmax,\n",
    "            'min_period'     : self.tMin,\n",
    "            'max_period'     : self.tMax,\n",
    "            'min_frequency'  : self.fmin,\n",
    "            'max_frequency'  : self.fmax,\n",
    "            'units'          : self.units,\n",
    "        })\n",
    "        \n",
    "        self.ds.close()\n",
    "        return self.wave_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program \n",
    "start=time.time()\n",
    "\n",
    "print(\"BEGIN\")\n",
    "print(sys.version)\n",
    "\n",
    "# Load the dataset\n",
    "# file paths\n",
    "file_address = {\n",
    "    \"2023\": {\"uo\":\"/kaggle/input/wave-energy-analysis/Raw Data/u_current.2023_2024.nc\", \n",
    "             \"vo\":\"/kaggle/input/wave-energy-analysis/Raw Data/v_current.2023_2024.nc\"},\n",
    "    \"2018\": {\"uo\":\"/kaggle/input/wave-energy-analysis/u_current.2018_2019.nc\", \n",
    "             \"vo\":\"/kaggle/input/wave-energy-analysis/v_current.2018_2019.nc\"},\n",
    "    \"2014\": {\"uo\":\"/kaggle/input/wave-energy-analysis/u_current.2014_2015.nc\", \n",
    "             \"vo\":\"/kaggle/input/wave-energy-analysis/v_current.2014_2015.nc\"}\n",
    "}\n",
    "# Region of Interest\n",
    "coverage = {\n",
    "    'lat' : slice(-10, 10), \n",
    "    'lon' : slice(150, 270)\n",
    "}\n",
    "event = '2023'\n",
    "\n",
    "var = \"uo\"\n",
    "\n",
    "equ_waves = {\n",
    "    'KW'  : {'wave_name':'KW', 'n':0, 'data':[]}, \n",
    "    'ER' : {'wave_name':'ER',  'n':1, 'data':[]}\n",
    "}\n",
    "\n",
    "# Results \n",
    "results = {\n",
    "    'uo': None,\n",
    "    'vo': None\n",
    "}\n",
    "\n",
    "\n",
    "for num, (var, path) in enumerate(file_address[event].items()):\n",
    "    print(f\"Variable {num+1}:\", var)\n",
    "    print(f\"path: {path}\")\n",
    "    # Raw Data\n",
    "    ds = xr.open_dataset(path, chunks=\"auto\").mean('depth')\n",
    "\n",
    "    # Climatology Data\n",
    "    ds_clim = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/climatology.1993_2021.nc\", chunks=\"auto\")\n",
    "    clim = ds_clim[var].mean(['time', 'depth'])\n",
    "\n",
    "    # Anomaly Data\n",
    "    ds_var, clim_aligned = xr.align(ds[var][:,:,:1920], clim, join='override')\n",
    "    anom = ds_var - clim_aligned\n",
    "    data = anom.to_dataset()\n",
    "\n",
    "    \n",
    "    for i, key in enumerate(equ_waves.keys()):\n",
    "        wave_name = equ_waves[key]['wave_name']\n",
    "        n         = equ_waves[key]['n']\n",
    "        print(f\"{i+1}: {wave_name}, n = {n}\")\n",
    "    \n",
    "        # create a wave filter object\n",
    "        wave_filter = WaveFilter(data, var, coverage, wave_name, n, units='m')\n",
    "    \n",
    "        # filtering process\n",
    "        wave_filter.load_data()  \n",
    "        wave_filter.detrend_data()\n",
    "        wave_filter.fft_transform()\n",
    "        wave_filter.apply_filter()\n",
    "        wave_filter.inverse_fft()\n",
    "    \n",
    "        # store the data\n",
    "        equ_waves[key]['data'] = wave_filter.create_output()\n",
    "    \n",
    "        print(f\"{i+1}/{len(equ_waves)} Completed\")\n",
    "\n",
    "    # CREATE DATASET\n",
    "    # Extract the dimension\n",
    "    t    = equ_waves['ER']['data'].time\n",
    "    lat  = equ_waves['ER']['data'].lat\n",
    "    lon  = equ_waves['ER']['data'].lon\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    waves = xr.Dataset(\n",
    "        data_vars={\n",
    "            key: (['time', 'lat', 'lon'], equ_waves[key]['data'].values, equ_waves[key]['data'].attrs)\n",
    "            for key in equ_waves if isinstance(equ_waves[key]['data'], xr.DataArray)\n",
    "        },\n",
    "        coords=dict(\n",
    "            time=t,\n",
    "            lat=lat,\n",
    "            lon=lon,\n",
    "        ),\n",
    "        attrs=dict(\n",
    "            description=f'FFT-Filtered Sea Current of {event}',\n",
    "            source = 'Global Ocean Physics Reanalysis',\n",
    "            unit='m/s'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    results[var] = waves \n",
    "    \n",
    "    # Export the data\n",
    "    comp = dict(zlib=True, complevel=5)\n",
    "    encoding = {var: comp for var in waves.data_vars}\n",
    "    #waves.to_netcdf(\n",
    "    #    f'EW.SLA.{event}.noaa.nc',\n",
    "    #    engine='netcdf4',\n",
    "    #    encoding=encoding\n",
    "    #)\n",
    "    waves.close()\n",
    "    ds_clim.close()\n",
    "    ds.close()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime: %8.1f seconds.\" % (end-start))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7c095",
   "metadata": {},
   "source": [
    "# Calculate the Energy Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584270d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy(u, v, h):\n",
    "    \"\"\" \n",
    "    Calculate Kinetic and Potential Energy of Equatorial Waves\n",
    "    \"\"\"\n",
    "    g = 9.81\n",
    "\n",
    "    \n",
    "    energy = {\n",
    "        'KW': None,\n",
    "        'ER': None\n",
    "    }\n",
    "\n",
    "    for var in ['KW', 'ER']:\n",
    "        print(var)\n",
    "\n",
    "        # group velocity\n",
    "        if var == \"KW\":\n",
    "            c = 2.25\n",
    "        else:\n",
    "            c = 0.55\n",
    "\n",
    "        # calculate the energy\n",
    "        energy[var] = 0.5 * ( u[var]**2 + v[var]**2 + (g * h[var])**2 )\n",
    "        #energy[var] = 0.5 * (u[var]**2 + v[var]**2 + (g * h[var])**2)\n",
    "    # export as dataset\n",
    "    ds = xr.Dataset({\n",
    "        'KW': energy['KW'],\n",
    "        'ER': energy['ER']\n",
    "    })\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = \"2023\"\n",
    "\n",
    "# sea level anomaly results\n",
    "waves_path = {\n",
    "    \"2023\" : \"/kaggle/input/eof-results/2023-2024/2023-2024.EW.SLA.nc\",\n",
    "    \"2018\" : \"/kaggle/input/eof-results/2018-2019/2018-2019.EW.SLA.nc\",\n",
    "    \"2014\" : \"/kaggle/input/eof-results/2014-2015/2014-2015.EW.SLA.nc\"\n",
    "}\n",
    "equ_waves = xr.open_dataset(waves_path[event], chunks=\"auto\")\n",
    "\n",
    "\n",
    "coverage = {\n",
    "    \"2023\" : dict(time = slice(\"2023-01\", \"2024-12\")),\n",
    "    \"2018\" : dict(time = slice(\"2018-01\", \"2019-12\")),\n",
    "    \"2014\" : dict(time = slice(\"2014-01\", \"2015-12\"))\n",
    "    \n",
    "}\n",
    "\n",
    "# extract the data\n",
    "u = results[\"uo\"].sel(**coverage[event])\n",
    "v = results[\"vo\"].sel(**coverage[event])\n",
    "h = equ_waves.sel(**coverage[event])\n",
    "\n",
    "# calculate the energy\n",
    "energy = calculate_energy(u, v, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data\n",
    "comp = dict(zlib=True, complevel=7)\n",
    "encoding = {var: comp for var in energy.data_vars}\n",
    "energy.to_netcdf(\n",
    "   f'{event}.Wave_Energy.nc',\n",
    "   engine='netcdf4',\n",
    "   encoding=encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01839a51",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "wave_energy = {\n",
    "    \"2023\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2023.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2023-06\", \"2024-05\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2023-2024.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2023-2024.EOF.ER.nc\")\n",
    "    ),\n",
    "    \"2018\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2018.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2018-10\", \"2019-07\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2018-2019.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2018-2019.EOF.ER.nc\")\n",
    "    ),\n",
    "    \"2014\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2014.Wave_Energy.nc\", chunks=\"auto\"), \n",
    "        period = dict(time=slice(\"2014-11\", \"2015-06\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2014-2015.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2014-2015.EOF.ER.nc\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918d088",
   "metadata": {},
   "source": [
    "## Monthly Energy Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(10, 9), nrows=3, sharex=False, constrained_layout=True)\n",
    "\n",
    "t = np.arange(1, 25)\n",
    "\n",
    "time = wave_energy['2023']['energy']['time']\n",
    "var = \"ER\"\n",
    "\n",
    "if var == \"KW\":\n",
    "    lat_band = slice(-2,2)\n",
    "    title = 'Kelvin Waves'\n",
    "else:\n",
    "    lat_band = slice(-5,5)\n",
    "    title = 'Equatorial Rossby Waves'\n",
    "\n",
    "budget2023 = wave_energy['2023']['energy'][var].sel(lat=lat_band).resample(time='1ME').sum().sum(['lat','lon']).values\n",
    "budget2018 = wave_energy['2018']['energy'][var].sel(lat=lat_band).resample(time='1ME').sum().sum(['lat','lon']).values\n",
    "budget2014 = wave_energy['2014']['energy'][var].sel(lat=lat_band).resample(time='1ME').sum().sum(['lat','lon']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcecc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite energy budget for the 2018 and 2014 events\n",
    "\n",
    "mean = []\n",
    "std  = []\n",
    "\n",
    "for i, (b1, b2) in enumerate(zip(budget2018, budget2014)):\n",
    "    composite = [b1, b2]\n",
    "    mean.append(np.mean(composite))\n",
    "    std.append(np.std(composite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,72, 1)\n",
    "x1 = x[::3]\n",
    "\n",
    "\n",
    "ticks = np.arange(1, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f845fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 1e5\n",
    "data1 = budget2023 / factor\n",
    "data2 = np.array(mean) / factor\n",
    "yerr2 = np.array(std) / factor\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4), dpi=300)\n",
    "ax.bar(x1, data1, color='tab:blue', label='2023/24 El Niño', align='edge', width=-1)\n",
    "ax.bar(x1, data2, yerr=yerr2, capsize=4, color='tab:grey', label='Other El Niño', align='edge', width=1)\n",
    "\n",
    "ax.set_xticks(x1)\n",
    "ax.set_xticklabels(ticks)\n",
    "ax.legend()\n",
    "ax.set_title(f\"{title} Energy Budget\", fontweight='bold')\n",
    "ax.set_ylabel(\"10⁵ W/m²\")\n",
    "ax.set_xlabel(\"Month-\")\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"Energy.Budget.{var}.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f43a8f",
   "metadata": {},
   "source": [
    "## Wave Energy vs Taux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "\n",
    "# Wave Energy Dataset\n",
    "wave_energy = {\n",
    "    \"2023\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2023.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2023-06\", \"2024-05\"))\n",
    "    ),\n",
    "    \"2018\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2018.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2018-10\", \"2019-07\"))\n",
    "    ),\n",
    "    \"2014\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2014.Wave_Energy.nc\", chunks=\"auto\"), \n",
    "        period = dict(time=slice(\"2014-11\", \"2015-06\"))\n",
    "    )\n",
    "}\n",
    "\n",
    "# Wind Stress Dataset\n",
    "wind_stress = xr.open_dataset(\"/kaggle/input/warmwatervolume/wind_stress.1994_2025.ERA5.nc\")\n",
    "wind_stress = wind_stress.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "\n",
    "# Zonal Wind Stress\n",
    "taux = wind_stress['eastward_stress']\n",
    "clim_taux = taux.sel(time=slice(\"1994-01\", \"2021-12\")).mean(\"time\")\n",
    "\n",
    "# Taux anomaly\n",
    "taux_2023 = taux.sel(time=slice(\"2023-01\", \"2024-12\")) - clim_taux \n",
    "taux_2018 = taux.sel(time=slice(\"2018-01\", \"2019-12\")) - clim_taux\n",
    "taux_2014 = taux.sel(time=slice(\"2014-01\", \"2015-12\")) - clim_taux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ed0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taux_idx(years, data, lat, lon, time):\n",
    "\n",
    "    taux_index = {\n",
    "        \"2023\": None,\n",
    "        \"2018\": None,\n",
    "        \"2014\": None\n",
    "    }\n",
    "    \n",
    "    for y, dat in zip(years, data):\n",
    "        idx = np.mean(dat.sel(lat=lat, lon=lon).isel(time=time))\n",
    "        taux_index[y] = float(idx.values)\n",
    "\n",
    "    return taux_index\n",
    "\n",
    "years = [\"2023\", \"2018\", \"2014\"]\n",
    "datas = [taux_2023, taux_2018, taux_2014]\n",
    "\n",
    "taux_index_er = taux_idx(years, datas, slice(-10,10), slice(150, 270), slice(0, 25))\n",
    "taux_index_kw = taux_idx(years, datas, slice(-2, 2),  slice(150, 270), slice(10, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy = {\n",
    "    '2023': {'KW':None, 'ER':None},\n",
    "    '2018': {'KW':None, 'ER':None},\n",
    "    '2014': {'KW':None, 'ER':None}\n",
    "}\n",
    "\n",
    "for year in [\"2023\", \"2018\", \"2014\"]:\n",
    "\n",
    "    yrstart = int(year) \n",
    "    yrstop  = int(int(year) + 1)\n",
    "    \n",
    "    for var in ['KW', 'ER']:\n",
    "        if var == 'KW':\n",
    "            we = wave_energy[year][\"energy\"][var].sel(lat=slice(-2,2), time=slice(f\"{yrstart}-11\", f\"{yrstop}-01\"))\n",
    "            we = we.sum(['time', 'lat','lon']).values\n",
    "        else:\n",
    "            we = wave_energy[year][\"energy\"][var].sel(lat=slice(-10,10)).sum(['time', 'lat','lon']).values\n",
    "        total_energy[year][var] = we\n",
    "        print(year, var, we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a164e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4), ncols=2, dpi=300, constrained_layout=True)\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green']\n",
    "\n",
    "for i, (year, data) in enumerate(total_energy.items()):\n",
    "    print(year)\n",
    "    yrtext = f\"{year[2:]}/{str(int(year)+1)[2:]}\"\n",
    "\n",
    "    xfactor = 1e-2\n",
    "    yfactor = 1e5\n",
    "    \n",
    "    # ER\n",
    "    ere = data['ER'] / yfactor\n",
    "    taux = taux_index_er[year] / xfactor \n",
    "    ax[1].scatter(taux, ere, color=colors[i], zorder=2)\n",
    "    print(taux)\n",
    "    # Annotate each point\n",
    "    if i == 2:\n",
    "        ax[1].annotate(yrtext, (taux-0.1, ere), textcoords=\"offset points\",  xytext=(0, 0), ha=\"left\", fontsize=8)\n",
    "    else:\n",
    "        ax[1].annotate(yrtext, (taux+0.02, ere), textcoords=\"offset points\",  xytext=(0, 0), ha=\"left\", fontsize=8)\n",
    "        \n",
    "    # KW\n",
    "    kwe = data['KW'] / yfactor\n",
    "    taux = taux_index_kw[year] /xfactor\n",
    "    print(taux)\n",
    "    ax[0].scatter(taux, kwe, color=colors[i], zorder=2)\n",
    "    if i == 2:\n",
    "        ax[0].annotate(yrtext, (taux, kwe+0.02), textcoords=\"offset points\",  xytext=(-5, 0), ha=\"left\", fontsize=8)\n",
    "    else:\n",
    "        ax[0].annotate(yrtext, (taux, kwe), textcoords=\"offset points\",  xytext=(-5, 0), ha=\"right\", fontsize=8)\n",
    "        \n",
    "    ax[0].set_title(r\"(a) KW Energy vs $\\tau_{x}$ Index\", fontweight='bold')\n",
    "    ax[1].set_title(r\"(b) ER Energy vs $\\tau_{x}$ Index\", fontweight='bold')\n",
    "    \n",
    "    if i != 2:\n",
    "        \n",
    "        if i == 0:\n",
    "            ax[i].set_xlim(-0.4, 0.6)\n",
    "            ax[i].set_xticks([-0.4, -0.2, 0.0, 0.2, 0.4, 0.6])\n",
    "            ax[i].set_xlabel(r\"Nov$^{0}$-Jan$^{1}$ $\\tau_{x}$ Index ($10^{-2}$ N/m$^2$)\")\n",
    "            ax[i].set_ylabel(r\"Nov$^{0}$-Jan$^{1}$ Wave Energy ($10^{5}$ W/m$^2$)\")\n",
    "        else:\n",
    "            ax[i].set_xlabel(r\"$\\tau_{x}$ Index ($10^{-2}$ N/m$^2$)\")\n",
    "            ax[i].set_ylabel(r\"Wave Energy ($10^{5}$ W/m$^2$)\")\n",
    "            \n",
    "        ax[i].axvline(0, color='black', alpha=0.8, zorder=1)\n",
    "\n",
    "\n",
    "for i in range(0,2):    \n",
    "    ax[i].grid(ls=\"--\", color='k', alpha=0.2, zorder=0)\n",
    "    \n",
    "plt.show()\n",
    "#fig.savefig(\"WaveEnergy_vs_Taux.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52170cbb",
   "metadata": {},
   "source": [
    "## Wave Energy Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ac951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "wave_energy = {\n",
    "    \"2023\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2023.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2023-06\", \"2024-05\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2023-2024.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2023-2024.EOF.ER.nc\")\n",
    "    ),\n",
    "    \"2018\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2018.Wave_Energy.nc\", chunks=\"auto\"),\n",
    "        period = dict(time=slice(\"2018-10\", \"2019-07\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2018-2019.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2018-2019.EOF.ER.nc\")\n",
    "    ),\n",
    "    \"2014\": dict(\n",
    "        energy = xr.open_dataset(\"/kaggle/input/wave-energy-analysis/2014.Wave_Energy.nc\", chunks=\"auto\"), \n",
    "        period = dict(time=slice(\"2014-11\", \"2015-06\")),\n",
    "        eof_kw = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2014-2015.EOF.KW.nc\"), \n",
    "        eof_er = xr.open_dataset(\"/kaggle/input/eof-results/Full Year/2014-2015.EOF.ER.nc\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import cmocean\n",
    "\n",
    "cmap = cmocean.cm.dense\n",
    "\n",
    "# Axes format\n",
    "lat_format = lambda v, _: f'{v:.0f}°N' if v > 0 else (f'{abs(v):.0f}°S' if v < 0 else '0')\n",
    "\n",
    "# Axis formatter\n",
    "def lon_format(v, _):\n",
    "    # v is longitude in degrees east (0-360)\n",
    "    if v > 180:\n",
    "        return f'{360 - v:.0f}°W'\n",
    "    elif v < 180:\n",
    "        return f'{v:.0f}°E'\n",
    "    else:\n",
    "        return '180°'\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9), nrows=3, sharey=True, constrained_layout=True, dpi=500)\n",
    "\n",
    "cbarticks = np.linspace(0, 5, 11)\n",
    "\n",
    "titles = [\"(a) 2023/24 El Niño\", \n",
    "          \"(b) 2018/19 El Niño\", \n",
    "          \"(c) 2014/15 El Niño\"]\n",
    "\n",
    "var = \"KW\"\n",
    "\n",
    "for n, (year, data) in enumerate(wave_energy.items()):\n",
    "    idx      =  data['eof_kw']['amp']\n",
    "    idx_mean = np.mean(idx.values)\n",
    "    idx_std  = np.std(idx.values)\n",
    "    limit    = idx_mean + idx_std\n",
    "    time = data[\"energy\"][var][\"time\"]\n",
    "\n",
    "    if var == \"KW\":\n",
    "        title = f\"{titles[n]}: Kelvin Waves Energy\"\n",
    "        selection = slice(f\"{int(year)}-11\", f\"{int(year)+1}-01\")\n",
    "    else:\n",
    "        title = f\"{titles[n]}: Equatorial Rossby Waves Energy\"\n",
    "        selection = slice(f\"{int(year)}-01\", f\"{int(year)+1}-12\") \n",
    "   \n",
    "    composite = data[\"energy\"][var].sel(time=selection) #.where(time[idx > 1])\n",
    "    print(year)\n",
    "    print(f\"{var}: {idx_mean:.2f} + {idx_std:.2f}\")\n",
    "    print(\"Total initiation: \", composite.shape[0])\n",
    "    composite = composite.mean(dim=\"time\") * 100\n",
    "    #composite = composite.where(time[idx > limit]).mean(\"time\")\n",
    "\n",
    "    lon = composite['lon']\n",
    "    lat = composite['lat']\n",
    "    c = ax[n].contourf(lon, lat, composite, cmap=\"Reds\", levels=cbarticks, extend='both')\n",
    "        \n",
    "    ax[n].set_title(title, fontweight=\"bold\")\n",
    "    ax[n].xaxis.set_major_formatter(FuncFormatter(lon_format))\n",
    "    ax[n].yaxis.set_major_formatter(FuncFormatter(lat_format))\n",
    "    ax[n].set_ylabel(\"Latitude\")\n",
    "    if n == 2:\n",
    "        ax[n].set_xlabel(\"Longitude\")\n",
    "    \n",
    "cbar = fig.colorbar(c, ax=ax, orientation='horizontal', aspect=40, pad=0.03, ticks=cbarticks[::2], label=r\"$10^{-2}$ W/m$^2$\")\n",
    "plt.show()\n",
    "fig.savefig(f\"Composite.Wave_Energy.{var}.png\", dpi=500, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
